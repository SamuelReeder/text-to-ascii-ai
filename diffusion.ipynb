{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ef23e1-ed22-40df-aed8-2c8adceaf6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, math, random\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ROOT = Path(\"/workspace/mnist_ascii_dataset\")\n",
    "TRAIN_MANIFEST = ROOT / \"train_manifest.jsonl\"\n",
    "TEST_MANIFEST  = ROOT / \"test_manifest.jsonl\"\n",
    "\n",
    "# Model params\n",
    "W = 20\n",
    "H = 10\n",
    "L = W * H\n",
    "\n",
    "EMB_DIM   = 64\n",
    "N_LAYERS  = 4\n",
    "N_HEADS   = 2\n",
    "FF_DIM    = 256\n",
    "BETAS     = (1e-4, 2e-2)\n",
    "TIMESTEPS = 400\n",
    "\n",
    "BATCH_SIZE   = 32          # consider vram\n",
    "EPOCHS       = 20\n",
    "LR           = 1e-3\n",
    "GRAD_CLIP    = 1.0\n",
    "GRAD_ACCUM   = 4           # effective batch = BATCH_SIZE * GRAD_ACCUM\n",
    "\n",
    "CFG_P_DROP   = 0.1         # classifier-free guidance drop prob\n",
    "CFG_NULL_ID  = 10          # null class id\n",
    "CFG_SCALE    = 3.0         # guidance at sampling\n",
    "\n",
    "LAMBDA_CE    = 0.5         # auxiliary CE loss on decoded tokens\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED); random.seed(SEED)\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "try:\n",
    "    torch.backends.cuda.enable_flash_sdp(True)\n",
    "    torch.backends.cuda.enable_mem_efficient_sdp(True)\n",
    "    torch.backends.cuda.enable_math_sdp(False)\n",
    "except:\n",
    "    pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91bd6f5-9921-4df9-b3e8-f0fa6bf849e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 10  (example: [' ', '#', '%', '*', '+', '-', '.', ':', '=', '@']...) | Sequence length L=200\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 6, 5, 0, 0, 0, 0, 0, 0, 0, 0, 8, 2, 5, 0, 0, 0, 0, 0,\n",
      "        0, 0, 8, 9, 5, 0, 0, 0, 0, 0, 0, 0, 7, 2, 9, 3, 0, 0, 0, 0, 0, 0, 1, 9,\n",
      "        4, 0, 0, 0, 0, 0, 0, 0, 0, 7, 9, 9, 4, 0, 6, 7, 4, 3, 9, 9, 5, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 5, 9, 9, 9, 9, 9, 9, 2, 9, 9, 4, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 3, 3, 8, 5, 6, 0, 0, 9, 9, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 4, 9, 9, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 6, 8, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor(4)\n",
      "Label: tensor(4)\n",
      "Unique id values: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Decoded (first 200 chars):\n",
      "······························.-········=%-·······=@-·······:%@*······#@+········:@@+·.:+*@@-·········-@@@@@@%@@+··········**=-.··@@%·················+@@*·················.=-··························\n",
      "RAW UNIQUE CODEPOINTS (sample 20):\n",
      "[(\"' '\", '0x20'), (\"'#'\", '0x23'), (\"'%'\", '0x25'), (\"'*'\", '0x2a'), (\"'+'\", '0x2b'), (\"'-'\", '0x2d'), (\"'.'\", '0x2e'), (\"':'\", '0x3a'), (\"'='\", '0x3d'), (\"'@'\", '0x40')]\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def load_manifest(path: Path) -> List[Dict]:\n",
    "    items = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                items.append(json.loads(line))\n",
    "    return items\n",
    "\n",
    "# ...existing code...\n",
    "# ...existing code...\n",
    "def normalize_ascii_grid(s: str, W: int, H: int, shift_left: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Normalize raw ASCII-art text into a fixed W*H grid (row-major string).\n",
    "    \"\"\"\n",
    "    s = unicodedata.normalize(\"NFKC\", s)\n",
    "\n",
    "    subst = {\n",
    "        '\\u00A0': ' ',  '\\u2002': ' ', '\\u2003': ' ', '\\u2004': ' ', '\\u2005': ' ',\n",
    "        '\\u2006': ' ', '\\u2007': ' ', '\\u2008': ' ', '\\u2009': ' ', '\\u200A': ' ',\n",
    "        '\\u202F': ' ', '\\u205F': ' ', '\\u3000': ' ',\n",
    "        '\\u2212': '-', '\\u2013': '-', '\\u2014': '-', '\\u2010': '-', '\\u2011': '-',\n",
    "        '\\uFF0E': '.', '\\u2024': '.', '\\uFF0B': '+', '\\uFF03': '#', '\\uFF0D': '-',\n",
    "        '\\uFF1A': ':', '\\uFF1D': '=', '\\uFF20': '@', '\\uFF0A': '*', '\\uFF05': '%'\n",
    "    }\n",
    "\n",
    "    out_chars = []\n",
    "    for ch in s:\n",
    "        if ch == '\\r':\n",
    "            continue\n",
    "        if ch == '\\n':\n",
    "            out_chars.append('\\n')\n",
    "            continue\n",
    "        ch = subst.get(ch, ch)\n",
    "        if 32 <= ord(ch) <= 126 and ch != '\\t':\n",
    "            out_chars.append(ch)\n",
    "        else:\n",
    "            out_chars.append(' ')\n",
    "    s = \"\".join(out_chars)\n",
    "\n",
    "    lines = s.splitlines()\n",
    "\n",
    "    while lines and not lines[-1].strip():\n",
    "        lines.pop()\n",
    "\n",
    "    if shift_left:\n",
    "        non_blank = [ln for ln in lines if ln.strip()]\n",
    "        if non_blank:\n",
    "            min_lead = min(len(ln) - len(ln.lstrip(' ')) for ln in non_blank)\n",
    "            if min_lead > 0:\n",
    "                lines = [ln[min_lead:] if len(ln) > min_lead else \"\" for ln in lines]\n",
    "\n",
    "    fixed = [(ln[:W] + \" \" * max(0, W - len(ln))) for ln in lines]\n",
    "    final_lines = fixed[:H] + [\" \" * W] * max(0, H - len(fixed))\n",
    "    grid = \"\".join(final_lines)\n",
    "\n",
    "    return grid\n",
    "# ...existing code...\n",
    "# ...existing code...\n",
    "\n",
    "\n",
    "\n",
    "class AsciiDigits(Dataset):\n",
    "    def __init__(self, manifest_path: Path, W: int, H: int, build_vocab_from: Path):\n",
    "        self.recs = load_manifest(manifest_path)\n",
    "        self.vocab = self._build_vocab(build_vocab_from, W, H)\n",
    "        self.stoi = {ch:i for i,ch in enumerate(self.vocab)}\n",
    "        self.itos = {i:ch for ch,i in self.stoi.items()}\n",
    "        \n",
    "    def _build_vocab(self, manifest_path: Path, W: int, H: int) -> List[str]:\n",
    "        chars = set([\" \"])\n",
    "        for i, entry in enumerate(load_manifest(manifest_path)):\n",
    "            txt = Path(entry[\"ascii_txt_path\"]).read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "            grid = normalize_ascii_grid(txt, W, H, shift_left=True)\n",
    "            # print(grid)\n",
    "            chars.update(set(grid))\n",
    "        return sorted(list(chars))\n",
    "\n",
    "    def __len__(self): return len(self.recs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        j = self.recs[idx]\n",
    "        txt = Path(j[\"ascii_txt_path\"]).read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "        # if idx == 0:\n",
    "        #     print(txt)\n",
    "        grid = normalize_ascii_grid(txt, W, H, shift_left=True)   # length L\n",
    "        # if idx == 0:\n",
    "        #     print(grid)\n",
    "        # Map to token ids (unknowns -> space)\n",
    "        # print(grid)\n",
    "        ids = torch.tensor([ self.stoi.get(ch, self.stoi[\" \"]) for ch in grid], dtype=torch.long)\n",
    "        label = torch.tensor(int(j[\"label\"]), dtype=torch.long)\n",
    "        return ids, label\n",
    "\n",
    "\n",
    "train_ds = AsciiDigits(TRAIN_MANIFEST, W, H, build_vocab_from=TRAIN_MANIFEST)\n",
    "test_ds  = AsciiDigits(TEST_MANIFEST,  W, H, build_vocab_from=TRAIN_MANIFEST)  # build vocab from train\n",
    "\n",
    "VOCAB = train_ds.vocab\n",
    "V = len(VOCAB)\n",
    "print(f\"Vocab size: {V}  (example: {VOCAB[:20]}...) | Sequence length L={L}\")\n",
    "tensor, label = train_ds[20]\n",
    "print(tensor)\n",
    "print(label)\n",
    "\n",
    "ids, lbl = train_ds[20]\n",
    "print(\"Label:\", lbl)\n",
    "print(\"Unique id values:\", torch.unique(ids))\n",
    "print(\"Decoded (first 200 chars):\")\n",
    "print(\"\".join(train_ds.itos[i.item()] for i in ids[:200]).replace(\" \", \"·\"))\n",
    "\n",
    "raw_path = Path(train_ds.recs[20][\"ascii_txt_path\"])\n",
    "raw = raw_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "print(\"RAW UNIQUE CODEPOINTS (sample 20):\")\n",
    "print(sorted({(repr(c), hex(ord(c))) for c in raw if c not in '\\n\\r'}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "088a094a-bb8b-4f3b-b573-b26dc8169ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_beta_schedule(timesteps: int, beta_start: float, beta_end: float):\n",
    "    betas = torch.linspace(beta_start, beta_end, timesteps, dtype=torch.float32)\n",
    "    alphas = 1.0 - betas\n",
    "    alpha_bar = torch.cumprod(alphas, dim=0)\n",
    "    return betas, alphas, alpha_bar\n",
    "\n",
    "BETAS_T, ALPHAS_T, ALPHAS_BAR_T = make_beta_schedule(TIMESTEPS, *BETAS)\n",
    "BETAS_T  = BETAS_T.to(device)\n",
    "ALPHAS_T = ALPHAS_T.to(device)\n",
    "ALPHAS_BAR_T = ALPHAS_BAR_T.to(device)\n",
    "\n",
    "def t_to_alpha_bar(t: torch.Tensor) -> torch.Tensor:\n",
    "    # t in [0, T-1], integer\n",
    "    return ALPHAS_BAR_T[t]\n",
    "\n",
    "def sinusoidal_embedding(timesteps: torch.Tensor, dim: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Standard transformer-style time embeddings.\n",
    "    timesteps: (B,)\n",
    "    returns: (B, dim)\n",
    "    \"\"\"\n",
    "    device = timesteps.device\n",
    "    half = dim // 2\n",
    "    freqs = torch.exp(\n",
    "        torch.linspace(math.log(1e-4), math.log(1.0), half, device=device)\n",
    "    )\n",
    "    # Shape: (B, half)\n",
    "    args = timesteps.float().unsqueeze(1) * freqs.unsqueeze(0)\n",
    "    emb = torch.cat([torch.sin(args), torch.cos(args)], dim=1)\n",
    "    if dim % 2 == 1:\n",
    "        emb = F.pad(emb, (0,1))\n",
    "    return emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af6263c2-44ff-4404-90e3-b9a0e56cbaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.checkpoint import checkpoint_sequential\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(1))\n",
    "    def forward(self, x):  # (L,B,D)\n",
    "        L = x.size(0)\n",
    "        return x + self.pe[:L]\n",
    "\n",
    "def sinusoidal_embedding(timesteps: torch.Tensor, dim: int) -> torch.Tensor:\n",
    "    half = dim // 2\n",
    "    freqs = torch.exp(torch.linspace(math.log(1e-4), math.log(1.0), half, device=timesteps.device))\n",
    "    args = timesteps.float().unsqueeze(1) * freqs.unsqueeze(0)\n",
    "    emb = torch.cat([torch.sin(args), torch.cos(args)], dim=1)\n",
    "    if dim % 2 == 1: emb = F.pad(emb, (0,1))\n",
    "    return emb\n",
    "\n",
    "class Denoiser(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_dim: int, n_layers: int, n_heads: int, ff_dim: int, seq_len: int, num_classes: int=11, use_ckpt=True):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.cls_emb   = nn.Embedding(num_classes, emb_dim)   # includes null class at id=CFG_NULL_ID\n",
    "        self.time_mlp  = nn.Sequential(nn.Linear(emb_dim, ff_dim), nn.SiLU(), nn.Linear(ff_dim, emb_dim))\n",
    "        self.pos = PositionalEncoding(emb_dim, seq_len)\n",
    "\n",
    "        layer = nn.TransformerEncoderLayer(d_model=emb_dim, nhead=n_heads, dim_feedforward=ff_dim,\n",
    "                                           batch_first=False, activation=\"gelu\", norm_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(layer, num_layers=n_layers, enable_nested_tensor=False)\n",
    "        self.out = nn.Linear(emb_dim, emb_dim)  # predict noise in embedding space\n",
    "        self.use_ckpt = use_ckpt\n",
    "\n",
    "        nn.init.normal_(self.token_emb.weight, std=0.02)\n",
    "        nn.init.normal_(self.cls_emb.weight, std=0.02)\n",
    "\n",
    "    def forward(self, x_t: torch.Tensor, t: torch.Tensor, y: torch.Tensor):\n",
    "        B,L,D = x_t.shape\n",
    "        t_emb = self.time_mlp(sinusoidal_embedding(t, D))   # (B,D)\n",
    "        c_emb = self.cls_emb(y)                             # (B,D)\n",
    "        h = x_t + (t_emb + c_emb).unsqueeze(1)              # (B,L,D)\n",
    "        h = h.transpose(0,1)                                 # (L,B,D)\n",
    "        h = self.pos(h)\n",
    "        if self.training and self.use_ckpt:\n",
    "            h = checkpoint_sequential(self.encoder.layers, len(self.encoder.layers), h)\n",
    "        else:\n",
    "            h = self.encoder(h)\n",
    "        h = h.transpose(0,1)                                 # (B,L,D)\n",
    "        return self.out(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca3fac52-3da2-409b-98a5-f4abce794e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collate(batch):\n",
    "    ids, labels = zip(*batch)\n",
    "    ids = torch.stack(ids, dim=0)        # (B, L)\n",
    "    labels = torch.stack(labels, dim=0)  # (B,)\n",
    "    return ids, labels\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True, collate_fn=collate)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True, collate_fn=collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffb84a3-c2e6-41cf-a336-ca361e53ad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Denoiser(vocab_size=len(train_ds.vocab), emb_dim=EMB_DIM, n_layers=N_LAYERS,\n",
    "                 n_heads=N_HEADS, ff_dim=FF_DIM, seq_len=L, num_classes=11, use_ckpt=True).to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=(device.type == \"cuda\"))\n",
    "\n",
    "SPACE_ID = train_ds.stoi[\" \"]\n",
    "Wt = model.token_emb.weight.t()   # (D,V)\n",
    "\n",
    "def position_weights(ids):\n",
    "    w = torch.full_like(ids, 0.3, dtype=torch.float32, device=ids.device)\n",
    "    return torch.where(ids != SPACE_ID, 1.0, w)\n",
    "\n",
    "def get_token_embeddings(ids):     # (B,L) -> (B,L,D)\n",
    "    return model.token_emb(ids.to(device))\n",
    "\n",
    "def decode_from_embeddings(e: torch.Tensor, temperature: float = 1.0) -> torch.Tensor:\n",
    "    # e has shape (B, L, D)\n",
    "    logits = e @ model.token_emb.weight.t()\n",
    "\n",
    "    # apply temperature to the logits\n",
    "    # higher temperature makes the distribution flatter\n",
    "    # lower temperature makes it sharper (like argmax)\n",
    "    if temperature > 0:\n",
    "        logits /= temperature\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        B, L, V = probs.shape\n",
    "        sampled_ids = torch.multinomial(probs.view(B * L, V), num_samples=1)\n",
    "        return sampled_ids.view(B, L)\n",
    "    else:\n",
    "        return logits.argmax(dim=-1)\n",
    "\n",
    "def train_one_epoch(epoch: int):\n",
    "    model.train()\n",
    "    total, n = 0.0, 0\n",
    "    opt.zero_grad(set_to_none=True)\n",
    "\n",
    "    for step, (ids, labels) in enumerate(train_loader):\n",
    "        ids = ids.to(device); labels = labels.to(device)\n",
    "        e0 = get_token_embeddings(ids)\n",
    "        B = e0.size(0)\n",
    "        t = torch.randint(0, TIMESTEPS, (B,), device=device, dtype=torch.long)\n",
    "        eps = torch.randn_like(e0)\n",
    "        x_t = torch.sqrt(ALPHAS_BAR_T[t]).view(-1,1,1)*e0 + torch.sqrt(1-ALPHAS_BAR_T[t]).view(-1,1,1)*eps\n",
    "\n",
    "        # classifier-free: drop some labels to null class\n",
    "        y_in = labels.clone()\n",
    "        drop = torch.rand(B, device=device) < CFG_P_DROP\n",
    "        y_in[drop] = CFG_NULL_ID\n",
    "\n",
    "        with torch.amp.autocast('cuda', enabled=(device.type == \"cuda\")):\n",
    "            eps_hat = model(x_t, t, y_in)\n",
    "            loss_mse = F.mse_loss(eps_hat, eps)\n",
    "\n",
    "            # x0_hat for CE aux loss\n",
    "            a_bar = ALPHAS_BAR_T[t].view(-1,1,1)\n",
    "            x0_hat = (x_t - torch.sqrt(1 - a_bar) * eps_hat) / torch.sqrt(a_bar + 1e-8)\n",
    "\n",
    "            logits = (x0_hat @ Wt).reshape(-1, len(train_ds.vocab))   # (B*L, V)\n",
    "            ce = F.cross_entropy(logits, ids.reshape(-1), ignore_index=SPACE_ID, reduction='none')\n",
    "            ce = ce.view(B, -1)\n",
    "            # w = position_weights(ids)\n",
    "            # loss_ce = (ce * w).mean()\n",
    "            loss_ce = ce.mean() \n",
    "\n",
    "            loss = loss_mse + LAMBDA_CE * loss_ce\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "\n",
    "        if (step + 1) % GRAD_ACCUM == 0:\n",
    "            scaler.step(opt); scaler.update()\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "\n",
    "        total += float(loss.detach()) * B\n",
    "        n += B\n",
    "\n",
    "    return total / max(1, n)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(n_batches: int = 50):\n",
    "    model.eval()\n",
    "    total, n = 0.0, 0\n",
    "    for i, (ids, labels) in enumerate(test_loader):\n",
    "        if i >= n_batches: break\n",
    "        ids = ids.to(device); labels = labels.to(device)\n",
    "        e0 = get_token_embeddings(ids)\n",
    "        B = e0.size(0)\n",
    "        t = torch.randint(0, TIMESTEPS, (B,), device=device, dtype=torch.long)\n",
    "        eps = torch.randn_like(e0)\n",
    "        x_t = torch.sqrt(ALPHAS_BAR_T[t]).view(-1,1,1)*e0 + torch.sqrt(1-ALPHAS_BAR_T[t]).view(-1,1,1)*eps\n",
    "        with torch.amp.autocast('cuda', enabled=(device.type == \"cuda\")):\n",
    "            eps_hat = model(x_t, t, labels)\n",
    "            loss = F.mse_loss(eps_hat, eps)\n",
    "        total += float(loss.detach()) * B\n",
    "        n += B\n",
    "    return total / max(1, n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72296a84-48fa-4812-bec3-cf13cf1be8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:552: UserWarning: torch.utils.checkpoint.checkpoint_sequential: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | train 1.1055 | val 0.5174\n",
      "Epoch 2/20 | train 0.7558 | val 0.4023\n",
      "Epoch 3/20 | train 0.6711 | val 0.3350\n",
      "Epoch 4/20 | train 0.6289 | val 0.3012\n",
      "Epoch 5/20 | train 0.5976 | val 0.2734\n",
      "Epoch 6/20 | train 0.5716 | val 0.2534\n",
      "Epoch 7/20 | train 0.5540 | val 0.2398\n",
      "Epoch 8/20 | train 0.5384 | val 0.2252\n",
      "Epoch 9/20 | train 0.5248 | val 0.2133\n",
      "Epoch 10/20 | train 0.5125 | val 0.2079\n",
      "Epoch 11/20 | train 0.5022 | val 0.2111\n",
      "Epoch 12/20 | train 0.4956 | val 0.1978\n",
      "Epoch 13/20 | train 0.4876 | val 0.1953\n",
      "Epoch 14/20 | train 0.4803 | val 0.1938\n",
      "Epoch 15/20 | train 0.4748 | val 0.1894\n",
      "Epoch 16/20 | train 0.4668 | val 0.1831\n",
      "Epoch 17/20 | train 0.4610 | val 0.1819\n",
      "Epoch 18/20 | train 0.4578 | val 0.1862\n",
      "Epoch 19/20 | train 0.4509 | val 0.1832\n",
      "Epoch 20/20 | train 0.4494 | val 0.1806\n",
      "Saved: /workspace/mnist_ascii_dataset/ascii_diffusion_e20_w20_h10.pt\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS+1):\n",
    "    tr = train_one_epoch(epoch)\n",
    "    va = evaluate()\n",
    "    print(f\"Epoch {epoch}/{EPOCHS} | train {tr:.4f} | val {va:.4f}\")\n",
    "\n",
    "CKPT = ROOT / f\"ascii_diffusion_e{EPOCHS}_w{W}_h{H}.pt\"\n",
    "torch.save({\n",
    "    \"model\": model.state_dict(),\n",
    "    \"vocab\": VOCAB,\n",
    "    \"config\": dict(W=W, H=H, L=L, emb_dim=EMB_DIM, steps=TIMESTEPS, betas=BETAS),\n",
    "}, CKPT)\n",
    "print(\"Saved:\", CKPT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ea3fee-f414-4a60-8c67-4b3c78960b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(CKPT, map_location=device)\n",
    "model.load_state_dict(ckpt[\"model\"])\n",
    "VOCAB = ckpt[\"vocab\"]\n",
    "W = ckpt[\"config\"][\"W\"]; H = ckpt[\"config\"][\"H\"]; L = ckpt[\"config\"][\"L\"]\n",
    "\n",
    "@torch.no_grad()\n",
    "def p_sample_loop(digit: int, steps: int = TIMESTEPS) -> torch.Tensor:\n",
    "    model.eval()\n",
    "    B = 1\n",
    "    x = torch.randn(B, L, EMB_DIM, device=device)\n",
    "    y_cond = torch.tensor([digit], device=device, dtype=torch.long)\n",
    "    y_null = torch.tensor([CFG_NULL_ID], device=device, dtype=torch.long)\n",
    "\n",
    "    for t_int in reversed(range(steps)):\n",
    "        t = torch.tensor([t_int], device=device, dtype=torch.long)\n",
    "\n",
    "        eps_uncond = model(x, t, y_null)\n",
    "        eps_cond   = model(x, t, y_cond)\n",
    "        eps_hat = eps_uncond + CFG_SCALE * (eps_cond - eps_uncond)\n",
    "\n",
    "        alpha_t = ALPHAS_T[t_int]\n",
    "        alpha_bar_t = ALPHAS_BAR_T[t_int]\n",
    "        beta_t = BETAS_T[t_int]\n",
    "        alpha_bar_tm1 = ALPHAS_BAR_T[t_int-1] if t_int > 0 else torch.tensor(1.0, device=device)\n",
    "\n",
    "        # posterior mean\n",
    "        mean = (1.0 / torch.sqrt(alpha_t)) * (x - ((1 - alpha_t) / torch.sqrt(1 - alpha_bar_t + 1e-8)) * eps_hat)\n",
    "        # posterior variance\n",
    "        posterior_var = beta_t * (1 - alpha_bar_tm1) / (1 - alpha_bar_t + 1e-8)\n",
    "        if t_int > 0:\n",
    "            x = mean + torch.sqrt(posterior_var.clamp(min=1e-20)) * torch.randn_like(x)\n",
    "        else:\n",
    "            x = mean\n",
    "    return x\n",
    "\n",
    "def ids_to_ascii(ids_1d: torch.Tensor) -> str:\n",
    "    s = \"\".join(VOCAB[i] for i in ids_1d.tolist())\n",
    "    return \"\\n\".join(s[i:i+W] for i in range(0, len(s), W))\n",
    "\n",
    "def sample_ascii(digit: int, steps: int = TIMESTEPS, temperature: float = 1.0) -> str:\n",
    "    e = p_sample_loop(digit, steps=steps)      # (1, L, D)\n",
    "    ids = decode_from_embeddings(e, temperature=temperature).squeeze(0)  # (L,)\n",
    "    return ids_to_ascii(ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "647140bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :.@.:.+.-..-- .  .:\n",
      ": -==..+-...-.+: .::\n",
      ":.#..++.:.@.#@@@-.-:\n",
      "..-. .=.-+:%..#%@-::\n",
      " .-.+#: #+ : =:=.=..\n",
      ".@- :=.:: %@+...-.%=\n",
      ":..:-=..@::%@::.*..%\n",
      "%:@.-%#:#=:.::-.#..-\n",
      "-+-+--+.:+..+.. *+:#\n",
      "# -*.%.#:.. :.@+:...\n"
     ]
    }
   ],
   "source": [
    "print(sample_ascii(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bba733f-3794-4beb-be23-17922aea28b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 7, 5,\n",
      "        8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 5, 7, 6, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 1, 7, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 3, 3, 1, 4, 4, 8, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 6, 2, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 2, 4, 5,\n",
      "        5, 8, 3, 1, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 8, 4, 4, 5, 7, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "tensor, label = train_ds[50]\n",
    "print(tensor)\n",
    "print(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ea03824-5d7f-457c-b003-5f748f1b8533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top widths: [(20, 10000)]\n",
      "Top heights: [(10, 10000)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "w_counts, h_counts = Counter(), Counter()\n",
    "for rec in train_ds.recs:  # or slice for a sample\n",
    "    s = Path(rec[\"ascii_txt_path\"]).read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    ls = s.splitlines()\n",
    "    h_counts[len(ls)] += 1\n",
    "    w_counts[max((len(ln) for ln in ls), default=0)] += 1\n",
    "\n",
    "print(\"Top widths:\", w_counts.most_common(5))\n",
    "print(\"Top heights:\", h_counts.most_common(5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
