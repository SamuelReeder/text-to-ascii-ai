{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72ef23e1-ed22-40df-aed8-2c8adceaf6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, math, random\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ROOT = Path(\"/workspace/mnist_ascii_dataset\")\n",
    "TRAIN_MANIFEST = ROOT / \"train_manifest.jsonl\"\n",
    "TEST_MANIFEST  = ROOT / \"test_manifest.jsonl\"\n",
    "\n",
    "# Model params\n",
    "W = 20\n",
    "H = 10\n",
    "L = W * H\n",
    "\n",
    "EMB_DIM   = 16            \n",
    "N_LAYERS  = 6              \n",
    "N_HEADS   = 4              \n",
    "FF_DIM    = 512             \n",
    "BETAS     = (1e-4, 2e-2)\n",
    "TIMESTEPS = 400\n",
    "\n",
    "BATCH_SIZE   = 32          # consider vram\n",
    "EPOCHS       = 32\n",
    "LR           = 4e-4\n",
    "GRAD_CLIP    = 1.0\n",
    "GRAD_ACCUM   = 4           # effective batch = BATCH_SIZE * GRAD_ACCUM\n",
    "\n",
    "CFG_P_DROP   = 0.1         # classifier-free guidance drop prob\n",
    "CFG_NULL_ID  = 10          # null class id\n",
    "CFG_SCALE    = 3.0         # guidance at sampling\n",
    "\n",
    "LAMBDA_CE    = 0.5         # auxiliary CE loss on decoded tokens\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED); random.seed(SEED)\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "try:\n",
    "    torch.backends.cuda.enable_flash_sdp(True)\n",
    "    torch.backends.cuda.enable_mem_efficient_sdp(True)\n",
    "    torch.backends.cuda.enable_math_sdp(False)\n",
    "except:\n",
    "    pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d91bd6f5-9921-4df9-b3e8-f0fa6bf849e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 10  (example: [' ', '#', '%', '*', '+', '-', '.', ':', '=', '@']...) | Sequence length L=200\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 6, 5, 0, 0, 0, 0, 0, 0, 0, 0, 8, 2, 5, 0, 0, 0,\n",
      "        0, 0, 0, 0, 8, 9, 5, 0, 0, 0, 0, 0, 0, 0, 7, 2, 9, 3, 0, 0, 0, 0, 0, 0,\n",
      "        1, 9, 4, 0, 0, 0, 0, 0, 0, 0, 0, 7, 9, 9, 4, 0, 6, 7, 4, 3, 9, 9, 5, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 5, 9, 9, 9, 9, 9, 9, 2, 9, 9, 4, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 3, 3, 8, 5, 6, 0, 0, 9, 9, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 4, 9, 9, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 6, 8, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor(4)\n",
      "Label: tensor(4)\n",
      "Unique id values: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Decoded (first 200 chars):\n",
      "································.-········=%-·······=@-·······:%@*······#@+········:@@+·.:+*@@-·········-@@@@@@%@@+··········**=-.··@@%·················+@@*·················.=-························\n",
      "RAW UNIQUE CODEPOINTS (sample 20):\n",
      "[(\"' '\", '0x20'), (\"'#'\", '0x23'), (\"'%'\", '0x25'), (\"'*'\", '0x2a'), (\"'+'\", '0x2b'), (\"'-'\", '0x2d'), (\"'.'\", '0x2e'), (\"':'\", '0x3a'), (\"'='\", '0x3d'), (\"'@'\", '0x40')]\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def load_manifest(path: Path) -> List[Dict]:\n",
    "    items = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                items.append(json.loads(line))\n",
    "    return items\n",
    "\n",
    "# ...existing code...\n",
    "# ...existing code...\n",
    "def normalize_ascii_grid(s: str, W: int, H: int, shift_left: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Normalize raw ASCII-art text into a fixed W*H grid (row-major string).\n",
    "    \"\"\"\n",
    "    s = unicodedata.normalize(\"NFKC\", s)\n",
    "\n",
    "    subst = {\n",
    "        '\\u00A0': ' ',  '\\u2002': ' ', '\\u2003': ' ', '\\u2004': ' ', '\\u2005': ' ',\n",
    "        '\\u2006': ' ', '\\u2007': ' ', '\\u2008': ' ', '\\u2009': ' ', '\\u200A': ' ',\n",
    "        '\\u202F': ' ', '\\u205F': ' ', '\\u3000': ' ',\n",
    "        '\\u2212': '-', '\\u2013': '-', '\\u2014': '-', '\\u2010': '-', '\\u2011': '-',\n",
    "        '\\uFF0E': '.', '\\u2024': '.', '\\uFF0B': '+', '\\uFF03': '#', '\\uFF0D': '-',\n",
    "        '\\uFF1A': ':', '\\uFF1D': '=', '\\uFF20': '@', '\\uFF0A': '*', '\\uFF05': '%'\n",
    "    }\n",
    "\n",
    "    out_chars = []\n",
    "    for ch in s:\n",
    "        if ch == '\\r':\n",
    "            continue\n",
    "        if ch == '\\n':\n",
    "            out_chars.append('\\n')\n",
    "            continue\n",
    "        ch = subst.get(ch, ch)\n",
    "        if 32 <= ord(ch) <= 126 and ch != '\\t':\n",
    "            out_chars.append(ch)\n",
    "        else:\n",
    "            out_chars.append(' ')\n",
    "    s = \"\".join(out_chars)\n",
    "\n",
    "    lines = s.splitlines()\n",
    "\n",
    "    while lines and not lines[-1].strip():\n",
    "        lines.pop()\n",
    "\n",
    "    if shift_left:\n",
    "        non_blank = [ln for ln in lines if ln.strip()]\n",
    "        if non_blank:\n",
    "            min_lead = min(len(ln) - len(ln.lstrip(' ')) for ln in non_blank)\n",
    "            if min_lead > 0:\n",
    "                lines = [ln[min_lead:] if len(ln) > min_lead else \"\" for ln in lines]\n",
    "\n",
    "    fixed = [(ln[:W] + \" \" * max(0, W - len(ln))) for ln in lines]\n",
    "    final_lines = fixed[:H] + [\" \" * W] * max(0, H - len(fixed))\n",
    "    grid = \"\".join(final_lines)\n",
    "\n",
    "    return grid\n",
    "# ...existing code...\n",
    "# ...existing code...\n",
    "\n",
    "\n",
    "\n",
    "class AsciiDigits(Dataset):\n",
    "    def __init__(self, manifest_path: Path, W: int, H: int, build_vocab_from: Path):\n",
    "        self.recs = load_manifest(manifest_path)\n",
    "        self.vocab = self._build_vocab(build_vocab_from, W, H)\n",
    "        self.stoi = {ch:i for i,ch in enumerate(self.vocab)}\n",
    "        self.itos = {i:ch for ch,i in self.stoi.items()}\n",
    "        \n",
    "    def _build_vocab(self, manifest_path: Path, W: int, H: int) -> List[str]:\n",
    "        chars = set([\" \"])\n",
    "        for i, entry in enumerate(load_manifest(manifest_path)):\n",
    "            txt = Path(entry[\"ascii_txt_path\"]).read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "            grid = normalize_ascii_grid(txt, W, H, shift_left=False)\n",
    "            # print(grid)\n",
    "            chars.update(set(grid))\n",
    "        return sorted(list(chars))\n",
    "\n",
    "    def __len__(self): return len(self.recs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        j = self.recs[idx]\n",
    "        txt = Path(j[\"ascii_txt_path\"]).read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "        # if idx == 0:\n",
    "        #     print(txt)\n",
    "        grid = normalize_ascii_grid(txt, W, H, shift_left=False)   # length L\n",
    "        # if idx == 0:\n",
    "        #     print(grid)\n",
    "        # Map to token ids (unknowns -> space)\n",
    "        # print(grid)\n",
    "        ids = torch.tensor([ self.stoi.get(ch, self.stoi[\" \"]) for ch in grid], dtype=torch.long)\n",
    "        label = torch.tensor(int(j[\"label\"]), dtype=torch.long)\n",
    "        return ids, label\n",
    "\n",
    "\n",
    "train_ds = AsciiDigits(TRAIN_MANIFEST, W, H, build_vocab_from=TRAIN_MANIFEST)\n",
    "test_ds  = AsciiDigits(TEST_MANIFEST,  W, H, build_vocab_from=TRAIN_MANIFEST)  # build vocab from train\n",
    "\n",
    "VOCAB = train_ds.vocab\n",
    "V = len(VOCAB)\n",
    "print(f\"Vocab size: {V}  (example: {VOCAB[:20]}...) | Sequence length L={L}\")\n",
    "tensor, label = train_ds[20]\n",
    "print(tensor)\n",
    "print(label)\n",
    "\n",
    "ids, lbl = train_ds[20]\n",
    "print(\"Label:\", lbl)\n",
    "print(\"Unique id values:\", torch.unique(ids))\n",
    "print(\"Decoded (first 200 chars):\")\n",
    "print(\"\".join(train_ds.itos[i.item()] for i in ids[:200]).replace(\" \", \"·\"))\n",
    "\n",
    "raw_path = Path(train_ds.recs[20][\"ascii_txt_path\"])\n",
    "raw = raw_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "print(\"RAW UNIQUE CODEPOINTS (sample 20):\")\n",
    "print(sorted({(repr(c), hex(ord(c))) for c in raw if c not in '\\n\\r'}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "088a094a-bb8b-4f3b-b573-b26dc8169ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_beta_schedule(timesteps: int, beta_start: float, beta_end: float):\n",
    "    betas = torch.linspace(beta_start, beta_end, timesteps, dtype=torch.float32)\n",
    "    alphas = 1.0 - betas\n",
    "    alpha_bar = torch.cumprod(alphas, dim=0)\n",
    "    return betas, alphas, alpha_bar\n",
    "\n",
    "BETAS_T, ALPHAS_T, ALPHAS_BAR_T = make_beta_schedule(TIMESTEPS, *BETAS)\n",
    "BETAS_T  = BETAS_T.to(device)\n",
    "ALPHAS_T = ALPHAS_T.to(device)\n",
    "ALPHAS_BAR_T = ALPHAS_BAR_T.to(device)\n",
    "\n",
    "def t_to_alpha_bar(t: torch.Tensor) -> torch.Tensor:\n",
    "    # t in [0, T-1], integer\n",
    "    return ALPHAS_BAR_T[t]\n",
    "\n",
    "def sinusoidal_embedding(timesteps: torch.Tensor, dim: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Standard transformer-style time embeddings.\n",
    "    timesteps: (B,)\n",
    "    returns: (B, dim)\n",
    "    \"\"\"\n",
    "    device = timesteps.device\n",
    "    half = dim // 2\n",
    "    freqs = torch.exp(\n",
    "        torch.linspace(math.log(1e-4), math.log(1.0), half, device=device)\n",
    "    )\n",
    "    # Shape: (B, half)\n",
    "    args = timesteps.float().unsqueeze(1) * freqs.unsqueeze(0)\n",
    "    emb = torch.cat([torch.sin(args), torch.cos(args)], dim=1)\n",
    "    if dim % 2 == 1:\n",
    "        emb = F.pad(emb, (0,1))\n",
    "    return emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af6263c2-44ff-4404-90e3-b9a0e56cbaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.checkpoint import checkpoint_sequential\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(1))\n",
    "    def forward(self, x):  # (L,B,D)\n",
    "        L = x.size(0)\n",
    "        return x + self.pe[:L]\n",
    "\n",
    "def sinusoidal_embedding(timesteps: torch.Tensor, dim: int) -> torch.Tensor:\n",
    "    half = dim // 2\n",
    "    freqs = torch.exp(torch.linspace(math.log(1e-4), math.log(1.0), half, device=timesteps.device))\n",
    "    args = timesteps.float().unsqueeze(1) * freqs.unsqueeze(0)\n",
    "    emb = torch.cat([torch.sin(args), torch.cos(args)], dim=1)\n",
    "    if dim % 2 == 1: emb = F.pad(emb, (0,1))\n",
    "    return emb\n",
    "\n",
    "class Denoiser(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_dim: int, n_layers: int, n_heads: int, ff_dim: int, seq_len: int, num_classes: int=11, use_ckpt=True):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.cls_emb   = nn.Embedding(num_classes, emb_dim)   # includes null class at id=CFG_NULL_ID\n",
    "        self.time_mlp  = nn.Sequential(nn.Linear(emb_dim, ff_dim), nn.SiLU(), nn.Linear(ff_dim, emb_dim))\n",
    "        self.pos = PositionalEncoding(emb_dim, seq_len)\n",
    "\n",
    "        layer = nn.TransformerEncoderLayer(d_model=emb_dim, nhead=n_heads, dim_feedforward=ff_dim,\n",
    "                                           batch_first=False, activation=\"gelu\", norm_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(layer, num_layers=n_layers, enable_nested_tensor=False)\n",
    "        self.out = nn.Linear(emb_dim, vocab_size)  # predict logits over vocab\n",
    "        self.use_ckpt = use_ckpt\n",
    "\n",
    "        nn.init.normal_(self.token_emb.weight, std=0.02)\n",
    "        nn.init.normal_(self.cls_emb.weight, std=0.02)\n",
    "\n",
    "    def forward(self, x_t: torch.Tensor, t: torch.Tensor, y: torch.Tensor):\n",
    "        B,L,D = x_t.shape\n",
    "        t_emb = self.time_mlp(sinusoidal_embedding(t, D))   # (B,D)\n",
    "        c_emb = self.cls_emb(y)                             # (B,D)\n",
    "        h = x_t + (t_emb + c_emb).unsqueeze(1)              # (B,L,D)\n",
    "        h = h.transpose(0,1)                                 # (L,B,D)\n",
    "        h = self.pos(h)\n",
    "        if self.training and self.use_ckpt:\n",
    "            h = checkpoint_sequential(self.encoder.layers, len(self.encoder.layers), h)\n",
    "        else:\n",
    "            h = self.encoder(h)\n",
    "        h = h.transpose(0,1)                                 # (B,L,D)\n",
    "        return self.out(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca3fac52-3da2-409b-98a5-f4abce794e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collate(batch):\n",
    "    ids, labels = zip(*batch)\n",
    "    ids = torch.stack(ids, dim=0)        # (B, L)\n",
    "    labels = torch.stack(labels, dim=0)  # (B,)\n",
    "    return ids, labels\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True, collate_fn=collate)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True, collate_fn=collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffb84a3-c2e6-41cf-a336-ca361e53ad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Denoiser(vocab_size=len(train_ds.vocab), emb_dim=EMB_DIM, n_layers=N_LAYERS,\n",
    "                 n_heads=N_HEADS, ff_dim=FF_DIM, seq_len=L, num_classes=11, use_ckpt=True).to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=(device.type == \"cuda\"))\n",
    "\n",
    "SPACE_ID = train_ds.stoi[\" \"]\n",
    "Wt = model.token_emb.weight.t()   # (D,V)\n",
    "\n",
    "def position_weights(ids):\n",
    "    w = torch.full_like(ids, 0.3, dtype=torch.float32, device=ids.device)\n",
    "    return torch.where(ids != SPACE_ID, 1.0, w)\n",
    "\n",
    "def get_token_embeddings(ids):     # (B,L) -> (B,L,D)\n",
    "    return model.token_emb(ids.to(device))\n",
    "\n",
    "def decode_from_embeddings(e: torch.Tensor, temperature: float = 1.0) -> torch.Tensor:\n",
    "    # e has shape (B, L, D)\n",
    "    logits = e @ model.token_emb.weight.t()\n",
    "\n",
    "    # apply temperature to the logits\n",
    "    # higher temperature makes the distribution flatter\n",
    "    # lower temperature makes it sharper (like argmax)\n",
    "    if temperature > 0:\n",
    "        logits /= temperature\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        B, L, V = probs.shape\n",
    "        sampled_ids = torch.multinomial(probs.view(B * L, V), num_samples=1)\n",
    "        return sampled_ids.view(B, L)\n",
    "    else:\n",
    "        return logits.argmax(dim=-1)\n",
    "\n",
    "def train_one_epoch(epoch: int):\n",
    "    model.train()\n",
    "    total, n = 0.0, 0\n",
    "    opt.zero_grad(set_to_none=True)\n",
    "\n",
    "    for step, (ids, labels) in enumerate(train_loader):\n",
    "        ids = ids.to(device); labels = labels.to(device)\n",
    "        e0 = get_token_embeddings(ids)\n",
    "        B = e0.size(0)\n",
    "        t = torch.randint(0, TIMESTEPS, (B,), device=device, dtype=torch.long)\n",
    "        eps = torch.randn_like(e0)\n",
    "        x_t = torch.sqrt(ALPHAS_BAR_T[t]).view(-1,1,1)*e0 + torch.sqrt(1-ALPHAS_BAR_T[t]).view(-1,1,1)*eps\n",
    "\n",
    "        # classifier-free: drop some labels to null class\n",
    "        y_in = labels.clone()\n",
    "        drop = torch.rand(B, device=device) < CFG_P_DROP\n",
    "        y_in[drop] = CFG_NULL_ID\n",
    "\n",
    "        with torch.amp.autocast('cuda', enabled=(device.type == \"cuda\")):\n",
    "            logits_hat = model(x_t, t, y_in) # (B, L, V)\n",
    "\n",
    "            # CE loss on logits\n",
    "            loss_ce = F.cross_entropy(logits_hat.reshape(-1, V), ids.reshape(-1))\n",
    "\n",
    "            # MSE loss on noise\n",
    "            # Convert predicted logits to predicted embeddings (x0_hat)\n",
    "            probs = F.softmax(logits_hat, dim=-1)\n",
    "            x0_hat = probs @ model.token_emb.weight # (B,L,V) @ (V,D) -> (B,L,D)\n",
    "\n",
    "            a_bar = ALPHAS_BAR_T[t].view(-1,1,1)\n",
    "            eps_hat = (x_t - torch.sqrt(a_bar) * x0_hat) / torch.sqrt(1 - a_bar + 1e-8)\n",
    "            loss_mse = F.mse_loss(eps_hat, eps)\n",
    "\n",
    "            loss = loss_mse + LAMBDA_CE * loss_ce\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "\n",
    "        if (step + 1) % GRAD_ACCUM == 0:\n",
    "            scaler.step(opt); scaler.update()\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "\n",
    "        total += float(loss.detach()) * B\n",
    "        n += B\n",
    "\n",
    "    return total / max(1, n)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(n_batches: int = 50):\n",
    "    model.eval()\n",
    "    total, n = 0.0, 0\n",
    "    for i, (ids, labels) in enumerate(test_loader):\n",
    "        if i >= n_batches: break\n",
    "        ids = ids.to(device); labels = labels.to(device)\n",
    "        e0 = get_token_embeddings(ids)\n",
    "        B = e0.size(0)\n",
    "        t = torch.randint(0, TIMESTEPS, (B,), device=device, dtype=torch.long)\n",
    "        eps = torch.randn_like(e0)\n",
    "        x_t = torch.sqrt(ALPHAS_BAR_T[t]).view(-1,1,1)*e0 + torch.sqrt(1-ALPHAS_BAR_T[t]).view(-1,1,1)*eps\n",
    "        with torch.amp.autocast('cuda', enabled=(device.type == \"cuda\")):\n",
    "            logits_hat = model(x_t, t, labels)\n",
    "\n",
    "            # Convert predicted logits to predicted embeddings (x0_hat)\n",
    "            probs = F.softmax(logits_hat, dim=-1)\n",
    "            x0_hat = probs @ model.token_emb.weight # (B,L,V) @ (V,D) -> (B,L,D)\n",
    "\n",
    "            a_bar = ALPHAS_BAR_T[t].view(-1,1,1)\n",
    "            eps_hat = (x_t - torch.sqrt(a_bar) * x0_hat) / torch.sqrt(1 - a_bar + 1e-8)\n",
    "\n",
    "            loss = F.mse_loss(eps_hat, eps)\n",
    "        total += float(loss.detach()) * B\n",
    "        n += B\n",
    "    return total / max(1, n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72296a84-48fa-4812-bec3-cf13cf1be8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:552: UserWarning: torch.utils.checkpoint.checkpoint_sequential: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32 | train 0.5282 | val 0.0021\n",
      "Epoch 2/32 | train 0.4787 | val 0.0036\n",
      "Epoch 3/32 | train 0.4734 | val 0.0033\n",
      "Epoch 4/32 | train 0.4713 | val 0.0055\n",
      "Epoch 5/32 | train 0.4700 | val 0.0034\n",
      "Epoch 6/32 | train 0.4700 | val 0.0041\n",
      "Epoch 7/32 | train 0.4695 | val 0.0074\n",
      "Epoch 8/32 | train 0.4689 | val 0.0040\n",
      "Epoch 9/32 | train 0.4689 | val 0.0044\n",
      "Epoch 10/32 | train 0.4680 | val 0.0058\n",
      "Epoch 11/32 | train 0.4677 | val 0.0094\n",
      "Epoch 12/32 | train 0.4682 | val 0.0103\n",
      "Epoch 13/32 | train 0.4689 | val 0.0162\n",
      "Epoch 14/32 | train 0.4681 | val 0.0103\n",
      "Epoch 15/32 | train 0.4680 | val 0.0145\n",
      "Epoch 16/32 | train 0.4674 | val 0.0071\n",
      "Epoch 17/32 | train 0.4670 | val 0.0103\n",
      "Epoch 18/32 | train 0.4664 | val 0.0124\n",
      "Epoch 19/32 | train 0.4665 | val 0.0158\n",
      "Epoch 20/32 | train 0.4653 | val 0.0096\n",
      "Epoch 21/32 | train 0.4658 | val 0.0082\n",
      "Epoch 22/32 | train 0.4654 | val 0.0087\n",
      "Epoch 23/32 | train 0.4671 | val 0.0130\n",
      "Epoch 24/32 | train 0.4653 | val 0.0174\n",
      "Epoch 25/32 | train 0.4671 | val 0.0152\n",
      "Epoch 26/32 | train 0.4658 | val 0.0165\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS+1):\n",
    "    tr = train_one_epoch(epoch)\n",
    "    va = evaluate()\n",
    "    print(f\"Epoch {epoch}/{EPOCHS} | train {tr:.4f} | val {va:.4f}\")\n",
    "\n",
    "CKPT = ROOT / f\"ascii_diffusion_e{EPOCHS}_w{W}_h{H}_v3.pt\"\n",
    "torch.save({\n",
    "    \"model\": model.state_dict(),\n",
    "    \"vocab\": VOCAB,\n",
    "    \"config\": dict(W=W, H=H, L=L, emb_dim=EMB_DIM, steps=TIMESTEPS, betas=BETAS),\n",
    "}, CKPT)\n",
    "print(\"Saved:\", CKPT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ea3fee-f414-4a60-8c67-4b3c78960b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(CKPT, map_location=device)\n",
    "model.load_state_dict(ckpt[\"model\"])\n",
    "VOCAB = ckpt[\"vocab\"]\n",
    "W = ckpt[\"config\"][\"W\"]; H = ckpt[\"config\"][\"H\"]; L = ckpt[\"config\"][\"L\"]\n",
    "\n",
    "@torch.no_grad()\n",
    "def p_sample_loop(digit: int, steps: int = TIMESTEPS) -> torch.Tensor:\n",
    "    model.eval()\n",
    "    B = 1\n",
    "    x = torch.randn(B, L, EMB_DIM, device=device)\n",
    "    y_cond = torch.tensor([digit], device=device, dtype=torch.long)\n",
    "    y_null = torch.tensor([CFG_NULL_ID], device=device, dtype=torch.long)\n",
    "\n",
    "    for t_int in reversed(range(steps)):\n",
    "        t = torch.tensor([t_int], device=device, dtype=torch.long)\n",
    "\n",
    "        # model outputs logits\n",
    "        logits_uncond = model(x, t, y_null)\n",
    "        logits_cond   = model(x, t, y_cond)\n",
    "        logits_hat = logits_uncond + CFG_SCALE * (logits_cond - logits_uncond)\n",
    "\n",
    "        probs = F.softmax(logits_hat, dim=-1)\n",
    "        x0_hat = probs @ model.token_emb.weight # (B,L,V) @ (V,D) -> (B,L,D)\n",
    "\n",
    "        alpha_t = ALPHAS_T[t_int]\n",
    "        alpha_bar_t = ALPHAS_BAR_T[t_int]\n",
    "        beta_t = BETAS_T[t_int]\n",
    "        alpha_bar_tm1 = ALPHAS_BAR_T[t_int-1] if t_int > 0 else torch.tensor(1.0, device=device)\n",
    "\n",
    "        # the predicted x0 formulation of the posterior mean\n",
    "        mean_pred_x0 = (torch.sqrt(alpha_bar_tm1) * beta_t) / (1. - alpha_bar_t) * x0_hat\n",
    "        mean_curr_x = (torch.sqrt(alpha_t) * (1. - alpha_bar_tm1)) / (1. - alpha_bar_t) * x\n",
    "        mean = mean_pred_x0 + mean_curr_x\n",
    "\n",
    "        # posterior variance\n",
    "        posterior_var = beta_t * (1 - alpha_bar_tm1) / (1 - alpha_bar_t + 1e-8)\n",
    "        if t_int > 0:\n",
    "            x = mean + torch.sqrt(posterior_var.clamp(min=1e-20)) * torch.randn_like(x)\n",
    "        else:\n",
    "            x = mean\n",
    "    return x\n",
    "def ids_to_ascii(ids_1d: torch.Tensor) -> str:\n",
    "    s = \"\".join(VOCAB[i] for i in ids_1d.tolist())\n",
    "    return \"\\n\".join(s[i:i+W] for i in range(0, len(s), W))\n",
    "\n",
    "def sample_ascii(digit: int, steps: int = TIMESTEPS, temperature: float = 1.0) -> str:\n",
    "    e = p_sample_loop(digit, steps=steps)      # (1, L, D)\n",
    "    ids = decode_from_embeddings(e, temperature=temperature).squeeze(0)  # (L,)\n",
    "    return ids_to_ascii(ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647140bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    \n",
      "         =  =       \n",
      "           @@#      \n",
      "           @@       \n",
      "           @        \n",
      "       @  @@        \n",
      "        @@@@        \n",
      "       @ @  @       \n",
      "       =  +         \n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "print(sample_ascii(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bba733f-3794-4beb-be23-17922aea28b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 6, 7, 5, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5,\n",
      "        5, 7, 6, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 1,\n",
      "        7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 3, 3, 1, 4, 4, 8, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 2, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 7, 2, 4, 5, 5, 8, 3, 1, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 8,\n",
      "        4, 4, 5, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "tensor, label = train_ds[50]\n",
    "print(tensor)\n",
    "print(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea03824-5d7f-457c-b003-5f748f1b8533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top widths: [(20, 10000)]\n",
      "Top heights: [(10, 10000)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "w_counts, h_counts = Counter(), Counter()\n",
    "for rec in train_ds.recs:  # or slice for a sample\n",
    "    s = Path(rec[\"ascii_txt_path\"]).read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    ls = s.splitlines()\n",
    "    h_counts[len(ls)] += 1\n",
    "    w_counts[max((len(ln) for ln in ls), default=0)] += 1\n",
    "\n",
    "print(\"Top widths:\", w_counts.most_common(5))\n",
    "print(\"Top heights:\", h_counts.most_common(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8676faf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sampling with CFG Scale = 4.5, Temperature = 0.7 ---\n",
      "                  -                         =      =+  +-  :+-           -   =                                                   .          . :==                                           .                               \n",
      "            -=                   ::          ==%- @ @#*****  %#     -     :=*:**+:                                    :.=.+=.       -     @@@#%@@#*@@                           -  = +. .: -.*..              :             \n",
      "     @* @@@#%@@              @ @@@@@        %# #   @%%  @  @         .*:.**-*%****++ %                .       * .  ++ =::=.=*+-:-+  @         @    %           += *.-- .  - +       :-#**%*##%%*-         +.   .   : *+     \n",
      "    # @#-@ #+%%+@@ %           @@               +     :     @       %   = -*-.=-*. .#    #   #*  @@ :@  @ @@      =@ =+:. -+ *=     :      * -     *   #   @*@#@*:.@@=%@@@=          *# +@+*#%@  =       *:# #**@@-#@-      \n",
      " @  @@ *   *  @%*               @@           .       *@  -   -           **#*#=*            @@@@@: @-@@=- *              @: *          -   =.@    .% *    @: # @@%:   *@@ #  .      +  *%@%#@  *       -  :@**.= -%@*%      \n",
      " .##+# @  +  @%@@*@@            @     @         * -+*:%%@ @:-@*          :.**:-      -   .* @*.#-@+@@@@+@      +        -:  + -     *  -=:#.#***.*@#  @        :=  %  %               * *%#%%*           **@-****@@ *       \n",
      "  @@@%@     +#@%# @          @% #@    @          @+@@*@@@*@+.*         =       **- .*        @:@@*.@:@-   @      =      --. -       *@ @@ @@@@##%*#*  @    . @      #@ @             @   .*@#%            .. --+@**.*       \n",
      "    #@@:@@%* -%@       @    @  @@@             *:##**#**** .**    .- +*@*:**=*-**#.= +             @  :           *-=+*@... -  *    *  **# +*#*++                 @ -- @ #       #   :@#%#%**@=                #@@  @       \n",
      "     + *: ++                =-  -            +=     = +           = .**-*.**.=..+:              @@@           .   +.-* *-- +                               @ @ @ @@@@@@@@@  @%     =*=*****-*=*        @      @@@@@ %@@     \n",
      "                                                                        * =                    ..        =                                                #% #@#*@@# .* @@.. @                        @%%%=-*@:%.+*=-   :   \n",
      "\n",
      "========================================\n",
      "\n",
      "--- Sampling with CFG Scale = 7.0, Temperature = 0.1 ---\n",
      "                .                           -:    - + +:= =+ :+    .        -  -   : -                         +                    -           @@    @                                      =        -                     \n",
      "        + :=-                  @.:##+        :   @@@%@@%*%*%%       - + =+*=.=.-:=: ++             @    +          + :== -=+:          @@@@@@@@@%@@@@ @                              : ---=..--*+                    .      \n",
      "    %  %% %@@%  @ %%   @#      @@@@   @     #@#+% * #%%@ @@          - -=**%***@@*.*#                  @@        -.-+-:-*+++-*--+      %#                      + =- -:+++= :-      #.+%*%@+**#*#*+ .     +   : *:- -= =     \n",
      "     @ @  @@@@@@@#-%            @@@                   @   -           =* +-. @+*%* *    %   @*@%@@+:    @  @      =:+++.=-:++ : +                          *=+@@#@*@*@-@:@%  %     ** @*@@%*@@ @         *=+*#.:+#:@%       \n",
      "@ @@@@@@%#      *#%            @@ @                   @%++    -+          %@**%*          @+@@@@. ++@@%-@+@@   %    ==-:*  *                 -   # . .**  @%:@@+%@-  =@@@@          %%##%*##%@*          #+ %@:  -*%@**     \n",
      "** @@@@       %%%-@*           @                  =*#@  *=- %+**         .  *:+  +: @   =**#@@@*@@*@@@@@@@@      :  = = * :         * : *@@@*#+%*%@@ **              #@@ +           # =+%**@++       +   #:%*@@%@@=        \n",
      "@@=@@@       @@@@@@          @@@   @  @         @@*@@*%%@##@+%#      * +       *@.**#        + :=@%@@   .        .     :  .             @@@@@@@***:*****            @@@ =            : @#*@% *#           @  -=*.@*-        \n",
      "   %@%@@## @%@#%:.*      @  @@@@ #@         #**+-#:%%.:-= =*.+ *  %%  ***+-=-@***: -.+            @+           *  .*+++++ ==* =  -  #* *****%** *:**.+ -             @            +   %:%@-*= @                  @ -        \n",
      "   * + +*-*=.-                               +=     +-.  :        + **-****=....* ++.             @@::    -.    = +:.:*:.*+.:                              @@   @@@@@@@@@@@@@@      ***=*%*#:% =          @@@@@@@@@@@@@@*   \n",
      "                                                                    * *    .              %@  *@ @:  +                                                    @@%@**@=*@@-@@@@ @*@  *                     @@  ****@*--=@@*  +@  \n"
     ]
    }
   ],
   "source": [
    "def sample_grid(cfg_scale: float, temp: float, steps: int = TIMESTEPS):\n",
    "    global CFG_SCALE\n",
    "    original_scale = CFG_SCALE\n",
    "    CFG_SCALE = cfg_scale\n",
    "    \n",
    "    print(f\"--- Sampling with CFG Scale = {cfg_scale}, Temperature = {temp} ---\")\n",
    "    \n",
    "    outputs = []\n",
    "    for i in range(10):\n",
    "        outputs.append(sample_ascii(i, steps=steps, temperature=temp))\n",
    "    \n",
    "    CFG_SCALE = original_scale\n",
    "\n",
    "    for r in range(H): \n",
    "        row_str = \"\"\n",
    "        for i in range(10): # for each digit\n",
    "            digit_lines = outputs[i].split('\\n')\n",
    "            row_str += digit_lines[r] + \"  \"\n",
    "        print(row_str)\n",
    "\n",
    "# --- Experiment with these values ---\n",
    "sample_grid(cfg_scale=4.5, temp=0.7)\n",
    "print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "sample_grid(cfg_scale=7.0, temp=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
